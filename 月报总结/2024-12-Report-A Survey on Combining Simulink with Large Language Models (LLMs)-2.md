# Simulink结合大语言模型（LLMs）的相关研究工作调研（下）

|Recorder|Date|Categories|
|----|----|----|
|Bin Yu|2024-12-30|Modeling Checking|

-----

## 引言

### 调研背景

Simulink 是一种广泛应用于动态系统建模与仿真的工具，在汽车、航空航天、电力电子等多个领域占据核心地位。然而，随着模型复杂性的提升，其在开发、分析和复用过程中面临诸多挑战，如模型规模庞大、调试难度高和模块间依赖复杂。

与此同时，大语言模型（LLMs）凭借其卓越的自然语言处理能力，展现出在代码生成、知识推理和智能推荐等领域的巨大潜力。通过将 LLM 与 Simulink 模型分析相结合，有望突破现有的技术瓶颈，例如实现对 Simulink 模型的语义级检索、智能化交互和自动优化，从而显著提升建模效率和设计创新能力。

本次调研旨在探索大语言模型与 Simulink 的结合方式，分析其潜在应用场景和技术挑战，并展望相关技术在智能系统开发中的未来发展。

### 调研目的

本次调研旨在探索大语言模型（LLMs）与 Simulink 系统建模技术的深度结合方式，分析其在语义检索、自动化建模、智能优化等核心领域的应用潜力。通过识别技术结合点和典型应用场景，评估 LLM 驱动的 Simulink 智能建模方案的可行性，同时总结当前技术面临的挑战，并提出解决方向。

## Simulink概述

Simulink是一种由MathWorks公司开发的图形化建模与仿真工具，主要用于构建和分析动态系统。它在工程和科学领域得到广泛应用，尤其是在以下方面表现突出：

- **模块化设计**：通过拖放模块和连接线，用户能够快速构建复杂系统模型。
- **多领域建模**：支持跨越机械、电气、液压等领域的联合建模。
- **硬件接口**：允许模型与真实硬件进行通信，实现硬件在环（HIL）仿真。
- **代码生成**：提供高效的自动代码生成工具，用于嵌入式系统开发。

### Simulink 的典型应用：

典型应用包括汽车工业的自动驾驶仿真、航空领域的控制系统设计，以及能源行业的可再生能源优化。尽管Simulink在工程设计中不可或缺，但面对大规模系统建模时，手动构建模型和调试仍然是一项耗时费力的任务。

## 大语言模型（LLMs）概述

![img](https://i-blog.csdnimg.cn/blog_migrate/a17f982bbe5ef37ec8d4e291a488991b.png)

图源：CSDN博客 - 大语言模型（LLM）的进化树，学习LLM看明白这一张图就够了

大语言模型（LLMs）是一种以深度学习为核心的自然语言处理技术，其发展依托于Transformer架构和大规模语料训练。这类模型在处理自然语言生成和理解任务时表现出强大的能力，具有以下特征：

- **语言生成与理解**：能够生成高质量的文本、翻译语言以及回答复杂问题。
- **广泛的任务适应性**：适用于编程辅助、内容创作、数据分析等多种场景。
- **智能推理与规划**：在一定程度上能够完成逻辑推理和任务执行建议。

当前应用范围包括自动化代码生成（如GitHub Copilot）、知识问答系统（如ChatGPT），以及学术和工业中的辅助分析。LLMs极大地提升了工作效率，但其在特定领域的专用性仍需进一步优化。

## Simulink与大语言模型结合的潜力与应用场景

将Simulink与大语言模型相结合，可以显著提升建模过程的智能化和便捷性，主要体现在以下几个方面：

- **自然语言转化建模**：通过自然语言输入，大语言模型可自动生成Simulink模型。
- **模型优化建议**：基于大语言模型对参数和架构的分析能力，为Simulink模型提供优化建议，减少试错过程。
- **快速学习支持**：通过大语言模型生成的实时指导和示例，新用户能够迅速熟悉Simulink的基本操作与高级功能。
- **自动化调试**：结合LLMs的文本分析能力，系统可快速诊断仿真错误并生成解决方案，从而降低调试难度。

这种技术融合为复杂工程问题的解决提供了创新手段，未来将进一步推动工程建模向高效化和智能化方向发展。

# 相关论文

# Slicing MATLAB Simulink Models

论文链接：https://ieeexplore.ieee.org/abstract/document/6227161

## 研究背景

MATLAB Simulink是汽车行业中开发复杂嵌入式系统最广泛使用的工业工具。这些系统通常包含数万个块和多个层次，常被部署在安全关键领域，需要全面的质量保证措施。手动审查复杂的Simulink模型由于其复杂的结构层次和模型引用，难以识别数据和控制流。

## 研究目的

本文旨在通过开发Simulink的静态切片技术来减少模型的复杂性。该方法移除不影响特定块的模型部分，使模型切片保持语义和结构层次，便于后续的自动化质量保证措施和手动审查。

## 研究问题

1. 如何进行MATLAB Simulink模型的控制和数据依赖分析。
2. 如何通过依赖图的方法对Simulink模型进行切片，以保留模型的层次和语义。

## 问题1 数据依赖&控制依赖

![image](https://github.com/user-attachments/assets/0924977f-5a0e-4b85-9dbc-e3e849d4bc01)

### 定义1：数据依赖 (Data Dependence)

条件：节点j数据依赖于节点i，如果满足以下三点：

- X在节点i被定义（即赋值）；
- x在节点j被引用（即使用）；
- 从i到j存在一条路径，在这条路径上x没有被重新定义（覆盖）。

![image](https://github.com/user-attachments/assets/2ddbdda5-6ef9-44dc-a15b-5a71d8a40880)

### 定义2：控制依赖 (Control Dependence)

条件：节点j控制依赖于节点i，如果满足以下两点：

- 存在一条路径从i到j，在这条路径上，j后支配 (postdominates) 路径上的所有节点（不包括i）；
- i不能被j后支配。

后支配 (Postdominate)：如果从i到程序出口的所有路径都必须经过j，则称节点j后支配节点i。

示例：

![image](https://github.com/user-attachments/assets/69053a14-772a-451d-bdf6-f42ae68536ca)

![image](https://github.com/user-attachments/assets/34423c07-b2ea-4c98-82a8-d17fa4f4f249)

![image](https://github.com/user-attachments/assets/26210df1-2414-4212-bfab-ea3c4ff81f61)

### Simulink模型中的依赖关系

#### 数据依赖：

定义：如果块B2的输入通过线路L从块B1的输出接收信号，则B2对B1有数据依赖。

在Simulink中，数据依赖通过**信号线**来表示，即如果一个块的输出是另一个块的输入，则第二个块对第一个块有数据依赖。

#### 控制依赖：

定义：如果块B2在一个条件执行上下文中，且这个上下文由块B1的条件控制，则B2对B1具有控制依赖。

控制依赖在Simulink中通过条件执行上下文（Conditional Execution Contexts, CECs）来确定，这些上下文代表了模型中的执行路径。

### 通过CEC分析依赖（控制依赖）

#### 条件执行上下文（CEC）：

条件子系统和循环只有在特殊端口或迭代块给出的条件评估为 “真”时才会执行。因此，相应的EC被称为条件执行上下文（CEC）。

![image](https://github.com/user-attachments/assets/00c1bc61-e423-4bed-bff0-d260df4a6ce5)

在对模型m的块进行调度时，Simulink会创建两个执行上下文：

- 模型的根上下文和条件子系统 S 的执行上下文，即CEC_S。

  调度流程：

  ![image](https://github.com/user-attachments/assets/bae1288d-70d1-4a2b-bd5e-aa6b1e4d80cc)

  对应的控制流程图：

  ![image](https://github.com/user-attachments/assets/e52a46c6-9a87-4257-afd1-ebfa0181b1cd)

从控制流图中可以看出，子系统CEC_S的执行依赖于cond，只有当cond为真时，子系统内的块才会被调度。所以，子系统与根上下文之间的这种依赖关系，直接体现了控制依赖。

关于cond的归属问题：即使cond节点本身包含在子系统m中，cond也必须被执行才能确定子系统是否必须被执行。因此cond必须被分配到父执行上下文中。

## 问题2 Simulink模型的切片方法

作者介绍了一种利用**依赖图**对Simulink模型进行切分的方法：

### 切片准则

![image](https://github.com/user-attachments/assets/5b20f2be-d3fb-47a1-bf4f-ddf6c7b7bf1f)

切片准则C(B)是一组选定的Simulink块。

虚拟块和非虚拟块都可以被选为切片准则，但**子系统块不能直接作为切片准则**。如果要针对子系统切片，则必须使用该子系统的Inport（输入端口）或Outport（输出端口）块。

如果切片准则为空，则生成的切片也为空。

### 块的相关性

块c与块b相关当且仅当c直接或间接地（通过数据依赖或控制依赖）依赖于b。这一概念包括虚拟块（如信号线连接的虚拟块），同时也允许保留Simulink模型的层次结构。

### Simulink切片

![image](https://github.com/user-attachments/assets/2bdb656b-ffea-4677-ab05-8a00c2178e9c)

后向切片：模型切片仅包含与切片准则C(B)**相关**的所有块。

前向切片：模型切片仅包含切片准则C(B)**所影响**的所有块。

层次结构保留：在生成的切片中，Simulink模型的层次结构（如子系统）会被保留。

![image](https://github.com/user-attachments/assets/7eb52062-b9e0-4698-b723-fb5a657e3b37)

### 计算依赖关系（条件执行上下文的计算）

![image](https://github.com/user-attachments/assets/12809c20-29ec-4f5f-abcd-b965aae90d13)

### Simulink模型切片算法解释

#### 示例  

假设一个 Simulink 模型包含以下组件：  

1. 条件子系统：由一个布尔信号控制。  
2. MultiPortSwitch 块：选择多个输入信号之一。  
3. 输入信号：包含一个Gain 块和一个Bias 块，最终输出通过Outport 块传递。  

#### 具体执行步骤 

##### 1. 模型初始化  

- 重新分配信号：将子系统端口重新映射到 Inport 和 Outport 块。  

##### 2. 遍历根上下文  

- 从模型根开始，调用findExecutionContexts(model, root_context)。  

##### 3. 进入条件子系统  

- 识别到条件子系统（例如 If 子系统）：  
  创建新的CEC（条件执行上下文），例如CEC_1，用于子系统。  
  将控制信号的块（如If条件判断块）添加到父CEC中。  
- 继续遍历子系统内部。  

##### 4. 遍历 MultiPortSwitch 块  

- 当发现 MultiPortSwitch 块时：  
  为每个数据端口（如输入1、输入2）创建一个新的CEC，例如CEC_2和CEC_3。  
  向后传播CEC：将与数据端口连接的块（如 Gain 和 Bias 块）添加到对应的CEC中。  

##### 5. 向外传播上下文  

- 如果PropExecContextOutsideSubsystem参数为ON，算法会：向前、向后检查信号路径，将CEC传递到相关的块。  

#### CEC传播示例解释  

##### MultiPortSwitch 数据端口上下文传播  

- 示例：CEC_2是 MultiPortSwitch 数据输入端口2的上下文。  
  如果该端口连接到Gain块：  
      CEC_2会向后传播到Gain块。  
      Gain块现在属于CEC_2。  

##### Gain块加入CEC的意义  

- 如果条件信号控制MultiPortSwitch的输出：  
  Gain块的输出会成为条件执行上下文的一部分。  
  这表示Gain块的输出仅在特定条件下被执行。  

#### 总结  

- 该算法通过递归遍历Simulink模型结构，识别条件执行上下文（CEC）。  
- 对于MultiPortSwitch或Switch块，CEC会从数据端口向上游传播，使相关的块（如Gain和Bias）加入到同一上下文中。  
- 这种方法确保了Simulink模型中所有条件执行的依赖关系被正确捕获。

### 建立依赖关系图并计算模型的静态切片

![image](https://github.com/user-attachments/assets/2dc7f55e-88a9-4de4-9b54-4c314a074451)
![image](https://github.com/user-attachments/assets/0392223a-56eb-4f08-9767-669374363f31)
![image](https://github.com/user-attachments/assets/3e544931-3f65-4b99-be76-a640ebd56cca)

#### 依赖图的生成步骤

##### 1. 创建执行上下文（CEC）

- 根上下文：模型最外层的执行上下文（root）。
- 子上下文：遇到条件执行子系统（如 While Iterator）时，创建新的 CEC。
  e.g. 在 Figure 3 中，While Iterator 形成了一个独立的 CEC。

具体算法实现：

- 遍历 Simulink 模型中的每个块。
- 如果发现条件执行子系统（如 While 块、Switch 块），为其创建新的上下文。

##### 2. 创建依赖图节点

- 遍历所有非子系统块，为每个块创建对应的依赖图节点。
  e.g. 在 Figure 9 中，每个模型块（如Constant, IC, sum+i, write(sum)）都对应一个节点。

##### 3. 添加数据依赖

- 对于每个信号，记录其数据流向，连接对应的节点。

e.g. 在Figure 3中：
 i的值被输入到累加器sum+i和乘法器mul*i，因此i节点有数据流向这些节点。
 sum+i节点的计算结果输出到write(sum)节点。

##### 4. 添加控制依赖

- 如果某个上下文（CEC）由条件执行块（如 While Iterator）触发：
  在依赖图中添加虚线边，表示控制依赖。
  这些数据依赖关系在Figure 9中以灰色实线表示。

e.g. 在Figure 3中：

- While Iterator子系统的所有内部节点都依赖于 Relational Operator 块的判断结果。
- 在Figure 9中，这种控制依赖用虚线边表示。

##### 5. 处理 Switch 和 MultiPortSwitch

- 如果遇到 Switch 或 MultiPortSwitch 块：
  创建额外的虚拟节点，表示选择的条件。
  在虚拟节点与实际数据输入块之间建立控制依赖。

### 小结

- 依赖图通过遍历模型中所有块和信号，生成数据依赖和控制依赖关系。
  数据依赖：表示数据的传递路径，例如i → sum+i → write(sum)。
  控制依赖：表示执行顺序的约束，例如 Relational Operator 控制 While Iterator 子系统内部的计算。
- 虚线和实线共同描述了模型中复杂的依赖关系，帮助理解执行上下文和数据流。

### C(write(mul)) 切片的产生过程

#### 1. 切片标准定义：C(write(mul))

- 切片标准（slicing criterion）：关注特定程序变量或信号的计算过程。
- 在本例中，切片标准是 C(write(mul))，表示我们关心write(mul)信号的计算过程及其所有依赖项。

#### 2. 反向可达性分析（Backward Reachability Analysis）

- 概念：
  从目标节点出发，逆向遍历依赖图，标记所有与目标节点相关的数据依赖和控制依赖节点。
  目的是保留计算目标节点所必需的所有依赖项。

- 应用于图中（Figure 9）：
  目标节点：write(mul)。
  过程：从write(mul)出发，沿着数据依赖和控制依赖路径逆向追踪，标记所有相关节点。

#### 3. 标记的依赖节点

- 关键节点的标记：
  在 Figure 9 中，write(mul) 依赖以下节点：
   mul * i：表示乘法操作。
   i：参与计算mul * i。
   Constant1：提供乘法的初始值。
   While Iterator：控制整个迭代过程的执行。
   Relational Operator 和 read(n)：判断迭代条件，控制While子系统。

- 去除无关节点：
  与 write(mul) 无关的节点不会被标记。
  例如，sum + i及其相关路径（如write(sum)）对write(mul)无影响，因此不会被标记。

#### 4. 移除未标记节点和子系统

- 过程：
  标记完成后，所有未被标记的节点都会被移除。
  如果某个子系统中的所有节点都未被标记，则该子系统也会被移除。

e.g. 在Figure 9中：
   粗体节点和线条表示切片中保留的部分。
   未标记的节点（如 sum, write(sum)）被移除。

#### 5. 切片结果分析

- 切片的最终结果（如 Figure 10 所示）：
  包含所有参与计算write(mul)的必要节点。
  与sum相关的计算（如sum + i, write(sum)）被完全排除，因为它们不影响write(mul)。

### 小结

C(write(mul)) 切片的生成过程如下：

1. 从目标节点write(mul)开始，进行反向可达性分析。
2. 标记所有与write(mul)相关的节点和路径，包括数据依赖和控制依赖。
3. 移除未被标记的节点（例如sum和其相关路径）。
4. 切片结果形成一个依赖子图，只保留计算write(mul)必需的节点。

通过这一过程，原始模型被简化，保留了目标计算的必要部分，去除了无关计算，提升了模型的可读性和分析效率。


## 结论

- 基于依赖图的切片方法在Simulink模型中有效提取数据和控制依赖关系，并能在**块级别**上进行切片。
  块级别：每个块是一个功能单元，执行特定操作（如加法、乘法、条件判断等）。

- 该方法相比其他建模符号的切片方法（如 UML、Statecharts），具有良好的性能和准确性，结果表现出较高的前景。

- 通过依赖图的构建，实验成功展示了不同 Simulink 结构（如控制依赖块）的处理过程，并能够生成相关的切片图。

## 不足之处与未来展望

- 执行上下文传播不够精确：现有算法对 Simulink 执行上下文的处理不完善，未能完全支持 MATLAB Simulink 文档中的规则 4 和 5（Definition 7）。在未来可以改进执行上下文传播算法，提升执行上下文的传播精度。

- 多速率块处理不足：当前方法未能识别多速率块，这些块包含不同采样率的信号，可能导致切片精度降低。未来可以研究采样率传播机制，确定多速率块（尤其是混合采样率的块）。

- 信号总线的精确性问题：Simulink的线条不能反映所携带的信号数量，运行时才确定总线上携带的具体信号。对总线块的处理尚未深入，数据依赖的精确性有待提高。在未来可以深入研究信号在总线块中的传播机制，精确确定数据依赖关系，提升切片的精确度。

- Stateflow 模块简化处理：当前方法将 Stateflow 模型 视为黑盒，假设所有输入信号与输出信号相关，但这种处理方式可能过于保守，导致切片不够精确。未来可以开发针对 Stateflow 的切片算法，以识别输入与输出之间的相关性，实现更全面的 Simulink/Stateflow 切片技术。

# Simulation-Based Testing of Simulink Models With Test Sequence and Test Assessment Blocks



> 使用测试序列和测试评估块对Simulink模型进行基于仿真的测试
>
> 作者：Federico Formica，Tony Fan，Akshay Rajhans
>
> 单位：McMaster University, MathWorks, University of Bergamo
>
> 期刊：IEEE TRANSACTIONS ON SOFTWARE ENGINEERING
>
> 论文链接：[https://ieeexplore.ieee.org/abstract/document/10374027](https://www.researchgate.net/profile/Tomasz-Tarczewski/publication/386181393_Large_Language_Model-Based_Tuning_Assistant_for_Variable_Speed_PMSM_Drive_with_Cascade_Control_Structure/links/674d71bda7fbc259f1a5c507/Large-Language-Model-Based-Tuning-Assistant-for-Variable-Speed-PMSM-Drive-with-Cascade-Control-Structure.pdf)

| Recorder | Date       | Categories |
| -------- | ---------- | ---------- |
| 苏哲欣   | 2024-12-20 | Simulink   |



## 1. Issue

- **Simulink模型验证的重要性**：Simulink被广泛应用于医疗、航空电子和汽车等行业的设计与测试，但模型验证仍是学术界和工业界广泛关注的问题，形式化方法和基于仿真的软件测试是主要技术路径。

- **现有方法缺陷**：

  - **形式化方法工具约束强**：如 Simulink Design Verifier 使用形式验证技术来检测设计错误，但对模型类型有严格约束，要求通过兼容性检查，无法验证不兼容的模型。工程师还需使用形式化语言（如信号时态逻辑）指定需求和输入配置，耗时且容易出错，工业应用中推广受限。

  - **手动测试用例难度大**：手动测试用例规范要求工程师通过测试序列块和测试评估块定义输入与检查过程，尽管此方法符合工业标准并由 Simulink® TestTM 支持，但对领域知识的依赖高，尤其在大型工业项目中任务繁重，需提供自动化支持以减少人工工作。

  - **基于证伪的技术适用性低**：现有的基于证伪的Simulink模型测试工具（如 ARISTEO、BREAK、FALSIFY 等）通过迭代地探索输入空间以检测故障揭示测试用例，但这些工具未直接支持Simulink本地测试块，且需要额外的学习成本和高人工配置要求，限制了其工业领域的应用。

    

## 2. Background

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/1.png)

- **起搏器模型**：图1描绘了控制器模型的一部分。起搏器连接到心房和心室，使用传感器来检查心脏活动，并使用执行器来传递肌肉激活的电信号。图1所示的Simulink包括输入端口MODE和ATR_CMP_DETECT以及输出端口ATR_PACE_CTRL。来自这些输入端口的输入信号分别是起搏器的期望操作模式和指定如何检测来自心脏的心房脉冲的信号。输出端口的输出信号指示心房是否应搏。

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2.png)

- **测试用例**：测试用例由测试序列块和测试评估块组成。例如，图2中的测试序列和测试评估块形成了图1的Simulink模型的测试用例。测试序列块为每个输入端口生成包含一个输入信号的测试输入，测试评估块评估模型的输出信号是否导致违反其verify和assert语句的表达式。

- 现有工具不能从使用测试序列和测试评估块定义的手动测试用例规范自动生成Simulink测试用例。

## 3. Introduction

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/3.png)

**HECATE**：使用手动测试用例规范自动生成新的故障揭示测试用例。

- 图3呈现了HECATE的概述。输入是测试序列（TS）和测试评估（TA）块以及被测Simulink模型（M）。输出要么是一个故障揭示测试用例（TC），要么是NFF（表明HECATE无法在分配的时间预算内检测到故障揭示测试用例）。
- HECATE由驱动阶段和搜索阶段组成：
  - 驱动阶段将测试块编译为工件，以两个步骤驱动基于模拟的搜索。步骤1要求工程师定义与测试序列块相关的搜索空间（SP）。步骤2将测试评估块转换为指导搜索的适应度函数（FF）；
  - 搜索阶段分两步实现基于模拟的软件测试框架的迭代测试过程。步骤3使用搜索空间定义（SP）迭代地生成新的候选测试序列（TS_C）。步骤4为由候选测试序列指定的测试输入执行模型（M,使用适应度函数（FF）检查测试评估是否满足或违反）。
- 如果检测到违规，或者如果计算超过其分配的时间预算（NFF），该工具将通过返回故障揭示测试用例（TC）而停止。否则，它继续进行新的迭代，并且步骤3使用先前生成的测试序列及其适应度值（即，TS1、F1,TS2、F2）以生成新的候选测试序列（TS_C）。

## 4. Driver phase

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/4.png)

- **搜索空间：**

  - **参数化测试序列**：工程师扩展原有的测试序列，手动引入搜索参数。

  - **参数域**：参数域由工程师通过指定参数的上下界来定义。

- **测试评估转换为适应度函数**

  ![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/5.png)

- 创建 FITNESSFUNCTION 子系统：创建 FITNESSFUNCTION（FF）子系统，创建两个子系统：**FITNESS_CONVERTER** 和 **AGGREGATOR**

- FITNESS_CONVERTER 子系统:将每个验证语句（verify/assert）转换为对应的适应度值输出端口。

- AGGREGATOR 子系统:从 FITNESS_CONVERTER 的多个适应度值中计算单一适应度值.

  ![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/6.png)



## 5. Search phase

搜索阶段包括两个主要步骤：**输入生成**（Input Generation）和**适应度评估**（Fitness Assessment）。

**输入生成（Input Generation）**

1. **输入**：搜索空间（SP）,由 HECATE 生成的测试序列（TS1, TS2, ...）及其对应的适应度值（F1, F2, ...）。

2. **目标**：通过为参数化测试序列内的参数分配值，生成一个新的候选测试序列（TS_C）。

3. **输出**：生成的新测试序列，例如图 2(a) 所示的测试序列。

**适应度评估（Fitness Assessment）**: 为测试序列计算适应度值,从输出信号 FIT_TOTAL中提取适应度值，适应度值为输出信号最后的取值。



## 6. Elevation

- RQ 1 HECATE在生成故障揭示测试用例方面有多有效？

- RQ 2 HECATE在生成故障揭示测试用例方面的效率如何？

- RQ 3 HECATE生成的故障揭示测试用例是否与其他现有工具生成的测试用例不同？

- RQ 4 HECATE在为大型汽车模型生成故障揭示测试用例方面有多大作用？

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/7.png)

**RQ1,RQ2:**

将HECATE和S-TALIRO进行了比较,HECATE有效地指导了基于搜索的探索。

为了回答RQ 2，比较了HECATE和S-TALIRO在生成揭示故障的测试用例方面的效率,HECATE所需的平均时间和迭代次数均低于S-TALIRO。

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/8.png)

**RQ3:**

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/9.png)

**RQ4:**

考虑了一个汽车领域的典型案例研究。

HECATE在13次迭代中返回了一个揭示失败的测试用例，需要257秒。

## 7. Conclusion

这项工作提出了一种Simulink模型的测试方法：HECATE。与现有方法不同，HECATE使用Simulink Test中的Test Sequence和Test Assessment模块来指导基于搜索的探索。HECATE依赖于参数化测试序列和将测试评估块编译为适应度函数的程序。

# FIM: Fault Injection and Mutation for Simulink  

> ATheNA-S：FIM：模拟电路的故障注入和突变  
> 作者：[<font style="color:rgb(107, 107, 107);">EzioBartocci</font>](https://dl.acm.org/doi/abs/10.1145/3540250.3558932#), [<font style="color:rgb(107, 107, 107);">LeonardoMariani</font>](https://dl.acm.org/doi/abs/10.1145/3540250.3558932#), [<font style="color:rgb(107, 107, 107);">DejanNičković</font>](https://dl.acm.org/doi/abs/10.1145/3540250.3558932#), [<font style="color:rgb(107, 107, 107);">DrishtiYadav</font>](https://dl.acm.org/doi/abs/10.1145/3540250.3558932#).  
> 单位： <font style="color:rgb(51, 51, 51);">维也纳大学（</font>[<font style="color:rgb(51, 51, 51);">德文</font>](https://baike.baidu.com/item/%E5%BE%B7%E6%96%87/26064?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">：Universität Wien；英文：University of Vienna）由</font>[<font style="color:rgb(51, 51, 51);">鲁道夫四世</font>](https://baike.baidu.com/item/%E9%B2%81%E9%81%93%E5%A4%AB%E5%9B%9B%E4%B8%96/22380221?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">成立于1365年，坐落于</font>[<font style="color:rgb(51, 51, 51);">奥地利共和国</font>](https://baike.baidu.com/item/%E5%A5%A5%E5%9C%B0%E5%88%A9%E5%85%B1%E5%92%8C%E5%9B%BD/2103115?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">首都</font>[<font style="color:rgb(51, 51, 51);">维也纳</font>](https://baike.baidu.com/item/%E7%BB%B4%E4%B9%9F%E7%BA%B3/6412?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">，是</font>[<font style="color:rgb(51, 51, 51);">奥地利</font>](https://baike.baidu.com/item/%E5%A5%A5%E5%9C%B0%E5%88%A9/149221?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">第一所大学及最高学府，也是</font>[<font style="color:rgb(51, 51, 51);">德语</font>](https://baike.baidu.com/item/%E5%BE%B7%E8%AF%AD/240836?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">世界</font>[<font style="color:rgb(51, 51, 51);">最古老的大学</font>](https://baike.baidu.com/item/%E6%9C%80%E5%8F%A4%E8%80%81%E7%9A%84%E5%A4%A7%E5%AD%A6/15659629?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">、</font>[<font style="color:rgb(51, 51, 51);">多瑙河</font>](https://baike.baidu.com/item/%E5%A4%9A%E7%91%99%E6%B2%B3/183208?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">地区的学术中心，产生了21位</font>[<font style="color:rgb(51, 51, 51);">诺贝尔奖</font>](https://baike.baidu.com/item/%E8%AF%BA%E8%B4%9D%E5%B0%94%E5%A5%96/187878?fromModule=lemma_inlink)<font style="color:rgb(51, 51, 51);">得主。</font>
>
> <font style="color:rgb(51, 51, 51);">米兰比科卡大学（Università degli Studi di Milano-Bicocca）是一所位于意大利米兰的公立高等教育机构。</font>
>
> <font style="color:rgb(51, 51, 51);">奥地利国家技术研究院(AIT)是奥地利最大的校外研究机构。</font><font style="color:rgb(51, 51, 51);">  
> </font><font style="color:rgb(51, 51, 51);">会议： ESEC/FSE22  
> </font><font style="color:rgb(51, 51, 51);">论文链接：</font>[https://dl.acm.org/doi/abs/10.1145/3540250.3558932](https://dl.acm.org/doi/abs/10.1145/3540250.3558932)

| Recorder           | Date       | Categories                                                   |
| ------------------ | ---------- | ------------------------------------------------------------ |
| 马智 李春奕 苏哲欣 | 2024-12-23 | Software and its engineering, Software testing and debugging; |


## 背景介绍

 网络物理系统的复杂性需要更有效的开发和验证方法来保证系统的可靠性和安全性。MathWorks Simulink® 成为了CPS的模型基础开发的事实标准。近十年来，形式化方法和软件测试方法，如伪造测试（falsification testing），这些方法已经被证明在查找CPS设计中的错误方面既成功又有效。



传统的测试方法通常依赖于预定义的测试场景和标准测试用例，这些方法往往针对常见的故障模式和预期的系统行为设计。然而，随着系统复杂度的增加，这些传统方法面临几个挑战：

1. **复杂系统的非线性和交互性**：现代系统，尤其是那些依赖于多个交互组件和高级算法（如机器学习和人工智能）的系统，表现出强烈的非线性特性和复杂的交互行为。传统的测试方法可能无法预见或复制这些复杂交互下的所有潜在故障。
2. **未知故障模式**：随着技术的发展，新的故障模式可能会出现，这些故障模式在系统设计初期未被考虑到。传统测试往往围绕已知故障模式进行，对于新出现的或未被充分理解的故障模式，传统方法可能检测不到。
3. **动态和实时系统**：对于需要实时响应的系统，例如自动驾驶汽车或实时医疗监控系统，故障的时效性和动态变化使得传统的静态测试方法不足以覆盖所有潜在的故障情况。
4. **规模化和自动化的限制**：随着系统规模的扩大，手动设计和执行所有可能的测试用例变得不切实际。此外，自动化测试脚本可能缺乏应对未预见事件的灵活性。

因此，发展新的故障注入技术变得至关重要，主要原因包括：

1. **增加测试覆盖率**：通过自动化的故障注入，可以在模型或系统运行时动态地模拟各种故障，包括那些在设计阶段未能预见的故障。这有助于提高测试的全面性和深度。
2. **模拟现实世界条件**：故障注入可以模拟真实世界中的异常条件，如硬件故障、网络延迟、数据损坏等，这些是传统测试方法难以完全模拟的。
3. **提高系统鲁棒性**：通过检测和修正因故障注入发现的问题，系统设计可以在真正的生产环境部署之前得到优化，增强系统对真实世界故障的抵抗能力。
4. **支持持续集成和持续部署（CI/CD）**：在CI/CD流程中，故障注入可以自动化地集成，确保系统在每次更新后都能经受住各种故障情况的测试。

通过这些方式，故障注入技术帮助应对和克服传统测试方法的局限，为复杂系统的设计验证提供更强大的工具和方法。这种技术的发展和应用对于确保现代复杂系统的安全性和可靠性至关重要。

 

系统地评估测试策略通常包括通过故障注入和变异测试来分析其在存在故障时检测不良系统行为的有效性。故障注入技术一般分为：基于硬件的故障注入、基于软件的故障注入以及基于仿真的故障注入。

1.基于硬件的故障注入技术

基于硬件的故障注入是在物理级完成的，通过改变环境参数(重离子辐射，电磁干扰，电源干扰等)干扰硬件或者通过改变[<font style="color:rgb(51, 51, 51);">集成电路芯片</font>](https://baike.baidu.com/item/%E9%9B%86%E6%88%90%E7%94%B5%E8%B7%AF%E8%8A%AF%E7%89%87/0?fromModule=lemma_inlink)管脚输入来达到故障注入的效果。

2.基于软件的故障注入技术

基于软件的故障注入，是通过在软件级生成错误，从而造成硬件级的故障。有很多注入方式，如修改内存数据，或者在软件代码中插入错误或修改逻辑，通过[<font style="color:rgb(51, 51, 51);">应用软件</font>](https://baike.baidu.com/item/%E5%BA%94%E7%94%A8%E8%BD%AF%E4%BB%B6/0?fromModule=lemma_inlink)生成故障或者通过底层软件如操作系统生成故障。

3.基于模拟的故障注入技术

这种技术使用在模拟测试的计算机原型上，通过在模拟过程中，改变逻辑值来达到故障注入的效果。

4基于仿真的故障注入技术

该技术主要是针对基于模拟故障注入技术中的时间开销问题。 



自动化工具支持的故障注入举例：  
Chaos Monkey：在云服务环境中随机关闭虚拟机或容器，测试系统的容错能力。  
Gremlin：一种企业级的故障注入工具，支持多种故障类型，包括硬件、网络和应用级故障。

## 本文动机

对于Simulink模型，目前还没有一个能满足所有已识别需求的故障注入解决方案，这限制了CPS测试方法的系统性实验。

## 本文方法

为了解决这个问题，文中介绍了一种名为FIM（故障注入和变异引擎）的开源工具，用于向Simulink模型注入故障。FIM提供了以下功能，所有这些功能都可以通过程序来配置：

1. 丰富的故障模型，包括传感器、硬件和网络故障，以及一个变异操作符库。
2. 系统性地在模型的不同部分注入故障：要么生成多个原始模型的副本，每个副本注入一个故障；要么生成一个原始模型的单一副本，将所有故障注入该副本。
3. 限制对模型特定部分的故障注入。
4. 故障的动态激活和停用。

FIM与现有工具相比，集成了更丰富的故障/变异类型，支持通过直接在MATLAB®环境中的透明用户界面进行自动化故障注入，无需任何额外设置，并提供可扩展的故障注入能力，允许通过配置文件设计实验，能在几秒钟内生成大量变种。这篇文章提供了一个关于如何使用FIM工具的全面指南，从其架构、关键功能到工作流程的洞见，并在航空领域的一个示例上评估了该工具的性能，最后总结了实验结果。

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734950329616-a2beda57-1e0f-4611-a26c-89ec60134900.png)

文中的图1展示了FIM的架构，包括三个主要组成部分：（1）故障库，（2）故障注入模块，（3）故障配置。  

### 故障库

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734950928935-4472dd14-b52f-4aa5-945c-dc3804602699.png)

故障库是一个自定义的Simulink库浏览器，包含了多种参数化的模块，用于不同类型的故障和突变操作符（如表1所列）。FIM允许用户扩展库浏览器，加入其他的故障或突变操作符。根据用户在所需突变列表中指定的故障类型，这些模块的插入或替换各不相同。表1中与“故障”相关的模块表示插入故障模块，而与“块突变”相关的则表示用指定的块突变操作符替换相关块。

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734950967166-9825752d-2335-4721-8b02-8f282fa3f31b.png)

图2展示了一些故障和块突变的示例。FIM支持的故障和突变操作符是现实的、典型的，并且根据现有文献，这些故障和操作符在实践中常见。特别是，故障如卡住（Stuck-at）、包裹丢失（Package drop）、偏差/偏移（Bias/Offset）、噪声（Noise）、时间延迟（Time delay）和位翻转（Bit flips）来源于ErrorSim、MODIFI、SIMULTATE和FIBlock等研究。而故障Negate、Invert和Absolute，以及块突变操作ROR、LOR和P2S则来源于SIMULTATE。S2P和ASR是突变测试中常用的标准算术操作符替换。

通过这样的设计，FIM提供了一个灵活的框架，允许研究者和工程师根据具体需求测试和验证各种故障场景，以提高系统的健壮性和可靠性。

### 故障注入

故障注入模块负责根据所需的突变（fault_list）注入故障。对于单模型案例（即单一模型的突变），FIM首先创建系统测试单元（SUT）的副本，并将所有所需的故障注入到复制的文件中。对于多模型案例（即多个模型的突变），FIM创建一个副本并在该副本中注入单一故障，然后继续此过程，直到所有所需的故障被注入，因此生成了多个副本的SUT，每个副本注入一个故障。

单模型模式相比多模型模式有两个优势：（a）生成和编译单一模型，以及（b）含有所有突变体的突变SUT允许用户调查多个故障的同时效应。多模型模式相比单模型模式的优势在于生成的单个模型的简单性和小尺寸。

故障注入模块利用程序化编辑Simulink模型的基础知识来注入突变SUT中的故障。本质上，它存储线柄、块柄、源-目的地块（及其相应的端口）的信息在一个持久缓存中。然后使用这些信息在复制的文件中注入故障。在注入故障时，故障注入模块自动保留信号的记录信息，并改进模型布局以遵循建模指南并增强模型的可读性。

一旦所有所需的故障被注入，故障注入模块会生成一个故障表（.xlsx文件），提供注入的故障块的详细信息。更确切地说，故障表提供以下详细信息：

（i）突变SUT的名称

（ii）在SUT中添加的故障块的唯一名称

（iii）注入故障的子系统

（iv）故障或块突变操作符的类型

（v）与注入故障的线相对应的源-目的地块的全名

（vi）源-目的地的相应端口号。这种详细的故障注入描述将帮助用户识别突变SUT中故障块的确切位置。值得注意的是，每个注入的故障块都有一个独特的名称，稍后将由故障配置组件使用以控制其激活。

### 故障配置

根据生成的故障表，用户现在可以配置实验中必须使用的故障。FIM允许用户输入另一个配置文件：fault_enable_list，这是一个表格（.csv或.xlsx文件），其中包含用于指定要激活的块以及相关故障参数的字段。根据fault_enable_list，故障配置组件在突变的系统测试单元（SUT）中启用相应的故障块，并为指定的故障参数配置它们。要激活的故障块通过其在故障表中的唯一标识符（故障编号）来指定。这一配置过程确保实验中可以精确地触发和观察特定故障的效应，从而有效地评估系统的健壮性和容错能力。  

## 工具使用

FIM（故障注入模块）对环境有一个特殊要求，即需要用户提供已授权的MATLAB®和Simulink®安装环境。本文在MATLAB® R2020b上实现了FIM，以提供一个命令行界面，允许用户从MATLAB®命令提示符调用该工具。无论是单模型还是多模型模式，故障注入和故障配置的任务都由不同的自定义函数控制。本质上，用户定义的配置文件和输出目录监控FIM的全部行为。

**故障注入**：FIM的输入包括一个配置文件和一个输出目录。通常，配置文件包含系统测试单元（SUT）的详细信息和故障列表（fault_list）。更具体地说，故障列表是一个表格，包含用于指定目标故障位置和所需的故障/突变类型的字段。目标故障位置可以使用源/目的地/父块的名称或SUT的层级来指定，从而给予用户控制故障注入空间的自由。作为输出，FIM根据选择的模式（单模型或多模型），产生一个单一突变模型或一组突变模型。此外，FIM还会将生成的故障表输出到用户指定的输出目录。

**配置故障**：在故障注入后，用户可以查看生成的故障表，以确定他希望启用的故障块。对于故障配置，用户还需要提供故障启用列表（fault_enable_list），该列表指定了下一次运行中必须激活的故障及其激活策略。作为输出，选定的故障块将被启用，相应的故障参数将在执行适当的命令后配置，具体取决于单模型或多模型模式。

## 工具评估

本案例研究聚焦于航空航天领域的飞机升降舵控制系统（AECS）。该Simulink模型涵盖了多个层级的子系统，包括控制器、植物模型、传感器等。模型输入为“飞行员指令”，其控制左右两个执行器的位置输出。模型还包括多种类型的信号，如实数值、布尔值和枚举状态机变量，这些信号的变异可能导致模型行为异常。

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734951958136-4239a1d1-7852-4f26-919b-a353faf0e57c.png)

为了验证工具的效能，本文在配备Apple M1芯片和16 GB RAM的MacBook Pro上，使用MATLAB® R2020b在macOS Big Sur环境下，对AECS进行了单模型和多模型模式的测试。本文通过平均十次独立运行的结果，测量了故障注入时间，并在表2中进行了总结。该表列出了目标故障位置、故障类型以及注入的故障数量。结果表明，单模型模式的故障注入机制在速度和计算成本上优于多模型模式，分别在单模型和多模型模式下平均注入时间为0.92秒和2.87秒。

根据本文的故障注入实验结果，本文得出以下结论：

1. 单模型模式在注入成本方面更优，适合对效率要求较高的场景。
2. 单模型模式在结构上较为复杂和杂乱，可能难以进行可视化、调试和分析，多模型模式则更有助于详细分析故障注入的结果。
3. 单模型模式适用于研究多个故障之间的相互干扰，这些故障可能在不同时间激活。
4. 用户可以先使用单模型模式进行初步分析，然后切换到多模型模式，以更全面地分析故障效应，提高分析的可理解性和解释性。

## 优势总结

FIM（故障注入和变异引擎）是一个专为Simulink模型设计的高级工具，用于精确地模拟和分析系统故障。该工具的主要优点概括如下：

1. **全面的故障库**：FIM配备了一个丰富的故障库，包括各种参数化模块，用于模拟包括传感器故障、硬件故障、网络故障等多种类型。库中还包含了多种突变操作符，支持用户根据需要扩展库内容，以适应各种测试场景。
2. **灵活的故障注入策略**：FIM支持单模型和多模型两种故障注入模式。用户可以选择在一个模型中注入所有故障，或者在多个模型中各注入一个故障，从而系统地探索故障对系统的具体影响。
3. **精确的故障配置和管理**：通过故障配置组件，FIM允许用户根据生成的故障表来精确配置实验中使用的故障，包括故障激活的块和相关参数。这种方式提供了高度的定制性和控制力，确保了实验的准确性和重现性。

#ATheNA-S: A Testing Tool for Simulink Models Driven by Software Requirements and Domain Expertise

> ATheNA-S：一个由软件需求和领域专业知识驱动的模拟链接模型的测试工具  
> 作者：Federico Formica, Mohammad Mahdi Mahboob, Mehrnoosh Askarpour, and Claudio Menghi.  
> 单位： 麦克马斯特大学（英语：McMaster University，简称McMaster或Mac）是加拿大安大略省哈密尔顿的一间研究型公立大>学,创办于1887年.  
> 会议： FSE 2024  
> 论文链接： [ATheNA-S: A Testing Tool for Simulink Models  
> Driven by Software Requirements and Domain Expertise ](https://dl.acm.org/doi/10.1145/3663529.3663804)

| Recorder           | Date       | Categories                                                   |
| ------------------ | ---------- | ------------------------------------------------------------ |
| 马智 李春奕 苏哲欣 | 2024-12-23 | Software and its engineering, Software testing and debugging; |


## 背景介绍

在软件测试领域，基于搜索的软件测试（Search-Based Software Testing, SBST）和动态符号执行技术（Dynamic Symbolic Execution, DSE）被广泛认为是当下最有效的两种自动化测试用例生成技术。这两种方法各有优势，但也存在无法忽视的局限性，制约了其实际应用与发展。

**基于搜索的软件测试（SBST）**  
的核心思想是将测试用例的生成问题转化为搜索优化问题。通过定义目标函数并利用搜索算法（如遗传算法、粒子群优化等）对程序输入空间进行搜索，SBST能够有效应对程序中的各种复杂约束条件。然而，SBST的主要局限性体现在以下两个方面：

1. 启发信息的缺失：SBST依赖于启发式算法，但当测试目标较为复杂或不易量化时，缺乏有效的指导可能导致搜索效率低下，难以快速找到满足特定测试需求的输入。 
2. 效率较低：由于搜索算法需要在较大的输入空间中进行多次评估和迭代，其计算开销往往较高，特别是在处理高维输入或复杂约束条件时，效率问题更为突出。

**动态符号执行技术（DSE）**  
通过结合符号执行和约束求解器的能力，以系统化的方式探索程序路径，生成高覆盖率的测试用例。具体而言，DSE能够通过对程序变量的符号化表达和路径条件的约束求解，直接推导出触发特定路径或满足特定目标的输入。这种方式在处理目标测试用例生成时表现出高度的效率和精准性。然而，DSE的局限性同样显著：

1. 复杂约束的求解瓶颈：DSE的效率和效果高度依赖于底层的约束求解器，而现代约束求解器在面对复杂非线性约束、函数调用深度较大的程序路径或状态爆炸问题时，性能往往受到严重制约。  
2. 路径爆炸问题：随着程序规模和复杂性的增加，DSE需要探索的路径数量呈指数增长，这进一步加剧了求解复杂约束的难度，成为限制DSE扩展性的核心挑战。

## 本文动机

**SBST中的适应度函数作用**

适应度函数是 SBST 的核心部分，它为启发搜索算法提供指导，用于评估测试用例距离目标（例如检测故障或覆盖特定路径）的距离。适应度函数的设计质量直接影响测试用例生成的效率和效果。然而，传统的适应度函数设计过程复杂且耗时，尤其是在面对具有多样化需求的复杂系统时。

**现有问题**

1. 自动生成的适应度函数能够从需求规范中提取目标，但可能缺乏领域知识的指导，导致适用性不足。
2. 手动设计的适应度函数能够融入工程师的领域知识，但过程繁琐且依赖个人经验。

**以前工作**

本文工作ATheNA-S 是之前ATheNA框架的一种实现, 专门针对 Simulink 模型，适用于使用 Matlab/Simulink 环境的工业用户。ATheNA 提出了一个新的适应度函数设计框架，通过结合自动生成的适应度函数和手动定义的适应度函数来优化 SBST 的搜索过程。具体来说，ATheNA 的方法包括以下几个核心部分：

1. 自动生成适应度函数

基于软件需求规范，自动生成适应度函数，确保测试目标的全面覆盖。  
自动化适应度函数减少了手动干预，降低了设计复杂性。

2. 手动定义适应度函数

工程师可以基于自身的领域知识和具体测试需求，手动设计适应度函数。  
手动适应度函数针对特定测试目标进行优化，提高了测试的灵活性和效果。

3. 组合适应度函数

将自动生成和手动定义的适应度函数进行组合，形成一个综合的适应度函数（称为 ATheNA 适应度）。  
ATheNA 适应度能够利用自动适应度函数的全面性，同时融入手动适应度函数的针对性，提升搜索效率和生成测试用例的质量。

4. 框架化实现

ATheNA框架提供了一个易于使用的平台，工程师可以通过简单的步骤（定义类、配置函数和运行算法）完成测试用例生成。

## 本文方法

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734943359668-ae3d61d9-fa67-4de8-b600-ff54e46197c1.png)**ATheNA-S 的核心组件与实现流程**

**1. 适应度函数的定义与实现:**

1. 自动适应度函数 (autFitness): 由系统的需求规范自动生成，基于预先定义的标准和模型来评估测试用例的效能。
2. 手动适应度函数 (manFitness): 由工程师根据他们对应用领域的深入了解手动定义，使得适应度函数能够更具体地反映出特定系统模型的需求。

**2. 适应度函数的组合策略:**

综合适应度函数 (athenaFitness): 结合自动和手动适应度函数的结果，通过特定的算法（如加权平均）来优化测试案例的生成。

**3. 搜索过程的控制:**

停止标准 (stopCriterion): 定义了何时终止搜索算法，可能基于达到一定的适应度阈值或执行了预定的迭代次数。

**参数化与框架配置**

选项类的扩展 (athena_options): 从 S-Taliro 的 staliro_options 类派生而来，包括了必要的配置选项，如适应度函数的选择和搜索算法的详细设置。这些参数化的设置允许工程师在运行测试之前调整和优化测试环境，确保适应度函数和搜索算法的配置最适合特定的测试需求。

**实施步骤**

1. 工程师首先通过继承 ATheNA-S 提供的基类来定义一个 Matlab 类，其中具体实现了自动和手动适应度函数的计算方法。
2. 接着，配置适应度函数的组合方式和搜索算法的停止条件。
3. 最后，运行搜索算法，根据配置的适应度函数生成适应系统需求的测试用例。

## 实验效果

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734945953446-279c0e69-79e5-419b-b6ae-3baf2116290e.png)

实验使用S-Taliro软件工具对图2中汽车动力总成的燃油控制模型（AFC）进行系统测试的过程。该模型由丰田公司开发，包含302个模块，用于控制燃烧引擎的空燃比，确保其接近参考值。在这里，研究的重点是如何利用S-Taliro检测模型在特定条件下是否满足预设的系统要求。

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734944844654-a43c4580-948a-48c2-b0e9-73ef67c6a726.png)

AFC系统的假设及其要求Listing 2通过三个参数详细定义了AFC的假设：(i)每个信号的范围（第1行）、（ii）插值节点数（第2行）、以及（iii）插值函数（第3行）。此外，工程师并没有测试不同的初始条件（第4行），50𝑠作为模拟时间（第5行）。

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734944889644-7ab2bfe8-c545-4f97-acf3-702160ddc1cc.png)

具体来说，研究团队考察了AFC系统在给定的时间间隔内（11秒至50秒）能否保持错误值（控制器误差）在0.007以内的需求。这一需求使用度量时序逻辑（MTL/STL）进行了形式化定义在Listing 3展示，利用全局时间操作符（G）和错误绝对值的约束来描述。此外，S-Taliro被用来表达AFC系统的假设，并根据这些假设检测需求违规情况。

**步骤1：** 工程师需要扩展类F_Assessment，定义一个合适的子类，以实现自动和手动适应度函数。在AFC示例中，工程师定义了子类AFC29_F_Assessment。自动适应度函数由方法autFitness指定，使用了Taliro（通过CallTaliro调用），该方法支持使用MTL/STL规范定义的要求。工程师提供了由Simulink模型运行生成的输出信号（o）和属性（phi）作为S-Taliro的输入，还有一些额外的配置参数被省略了。手动适应度函数manFitness旨在引导搜索向更可能导致软件故障的输入域的区域。为了优先考虑低油门值的输入信号，工程师定义了变量fit，该变量包含在模拟开始后10秒时输入信号矩阵第二列（2）中存储的值的最小值（min(i (t>=10,2))），即10秒至50秒间油门输入信号的最小值。这个值在[0, 1]范围内进行缩放，考虑油门的值范围（A(2).R）。由于搜索的目标是最小化适应度值，手动适应度函数确保在搜索过程中优先考虑低油门值的输入信号（区域）  。

  ![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734945907944-bdf55e1b-545e-4300-b7ec-313797b348ae.png)

**步骤2：** 工程师需要定义如何结合自动和手动适应度函数。对于AFC示例，工程师定义了athenaFitness方法如Listing 4 所示，该方法计算自动和手动适应度函数值的算术平均值。由于自动和手动适应度函数的值都在[−1, 1]范围内，ATheNA-S的适应度值也在此范围内。此外，手动和自动适应度函数被同等优先考虑。

![](https://cdn.nlark.com/yuque/0/2024/png/51796516/1734945996988-76f2eb83-a337-4e5b-848b-349141cd4860.png)

**步骤3：** 工程师通过执行命令运行搜索，输入包括模型名称（model）、属性的规范（phi, preds）和ATheNA-S选项（athena_opt），其中还包括了适应度函数的定义，输出包括一个结构（Results），其中包含发现的失败揭示测试用例（如果找到的话）。对于AFC模型，ATheNA-S在执行了15次搜索算法迭代后返回了一个失败揭示的测试用例，所需时间为55秒。该测试用例的输入信号显示在图3a中。图3b证实，在[40, 45]s的时间间隔内，错误信号μ超过了-0.007的阈值，导致需求违规。

## 讨论

ATheNA主要面向开发Simulink模型的软件工程师，仅支持Simulink模型，并不支持其他类型的模型。尽管ATheNA使用的搜索工具S-Taliro最近已扩展到考虑其他类型的软件工件，如Python代码，但ATheNA目前不支持它们。未来可能会支持其他类型的模型和软件工件。

ATheNA-S只要求工程师扩展一个抽象类（作为接口）即可使用。它提供了一个框架，使工程师能够轻松地使用这个适应度函数来引导搜索探索，而无需理解和改变基于搜索的平台的内部行为。

ATheNA-S的效率和效果取决于工程师编写适应度函数的能力。工程师理论上可以编写无限数量的手动适应度函数，以及结合自动和手动适应度函数的函数。对我们解决方案的广泛经验研究和评估是我们主要出版物的一部分，并且不在本文的讨论范围内。

# Simulink模型生成相关工具及方法调研

<p style="text-align:right; font-size: 12px;">日期:2024/12/xx</p>

| 记录者 | 调研方向                  |
| ------ | ------------------------- |
| 刘颜祯 | 模型库构建 & 模型检索引擎 |
| 樊郅昊 | 模型切片 & 思维链方法     |

## 调研概述

Simulink 作为一款广泛应用于自动化控制、通信、电力电子等多领域的动态系统建模与仿真工具，随着模型规模和复杂度的不断攀升，面临着诸多挑战。模型检索效率低，在众多模型中定位目标模型耗时且困难，缺乏语义级别的检索手段；模型分析难度高，复杂的结构使得理解、分析与复用不易实现；自然语言交互缺失，传统的检索与分析方式依赖界面操作和编码，交互效率较低。

为应对这些问题，计划借助大语言模型（LLMs）强大的自然语言处理能力，构建一个支持 Simulink 模型快速检索、分析和智能化交互的系统。具体目标包括：实现语义级别的模型检索，通过自然语言描述迅速定位相关 Simulink 模型或模块；开展智能分析与推荐，自动解析 Simulink 模型元数据，并基于语义提供模型优化建议；提升交互效率，利用大语言模型实现对 Simulink 模型的问答和动态分析支持。

## Simulink 模型库构建调研与进展

### 相关论文1：EvoSL：一个大型开源语料库Simulink 模型和项目的变化

[Shrestha23EvoSL.pdf](https://ranger.uta.edu/~csallner/papers/Shrestha23EvoSL.pdf)

    论文强调了现有研究工具和技术进行复制、再现、扩展和验证研究时，现成可用语料库的重要性，并介绍了 EvoSL 这一大型开源语料库，其包含 Simulink 项目的模型和项目变更，可用于研究 Simulink 模型及项目变化。

**研究背景**

- **Simulink 的重要性与研究现状**：Simulink 是多行业系统建模分析等的标准工具，但关于其项目开发及模型变化研究较少，且现有研究多为案例研究。
- **开源 Simulink 语料库现状**：虽有相关服务提供开源 Simulink 模型，但均无法直接用作语料库，现有语料库不含模型变更数据。如：展示了两个版本的 sf car Simulink 教程模型之间的差异，如添加了 Output 块（Out1）和更新了 Vehicle - to - transmission 连接线。
  ![image-20241225195631850](https://github.com/Anorexia16/PicStream/releases/download/asd/20241226-115146.jpg)

**EvoSL 语料库**

- **收集与筛选过程**：通过 EvoSL-Miner 从 GitHub 下载项目，经多步筛选，包括检查文件格式、许可证、模型提交次数、去重等，最终得到 924 个 Git 仓库的 EvoSL 语料库。
- **长期存储与元数据**：存储于 Zenodo，许可证为 CC BY 4.0，包含项目及元数据（如项目流行度、问题、请求等），元数据按项目分支分解提交信息并汇总。
- **模型和项目变更概述**：GitHub 上 Simulink 项目提交分布不均，EvoSL 项目提交情况类似；通过分析项目持续时间内变更分布，发现 EvoSL 项目更接近传统软件开发项目，有多个作者且部分提交涉及模型文件。

![image-20241225193156679](https://github.com/Anorexia16/PicStream/releases/download/asd/20241226-115306.jpg)

该图展示了如何使用 C - study 的模型比较工具从 EvoSL 中挖掘 Simulink 模型变化，呈现了实验过程中工具的使用流程和数据提取路径。

- **实验设置**：对闭源 Simulink 项目变更的研究进行复制，采用相同概念框架和工具，因工具差异排除部分文件，仅关注非合并默认分支提交。
- **样本分析**：从 EvoSL 中选取 36 个项目（EvoSL36），其与原研究项目特征在同一数量级，适合用于研究。
- 研究问题结果：图 9 展示了 EvoSL36 项目中默认分支上 Simulink 块更改的情况，按块类型分类显示了更改次数超过 50 次的块类型及其频率。
  ![image-20241225195426624](https://github.com/Anorexia16/PicStream/releases/download/asd/20241226-115308.jpg)

  - **RQ1**：元素变更方面，EvoSL36 与原研究结果相似，块和线变更最多，配置变更类型特殊，且两者变更类型比例趋势一致。
  - **RQ2**：块类型变更分布上，EvoSL36 与原研究有相似之处，部分块类型变更频率和顺序相关，表明 EvoSL36 可模拟原研究的块类型变更分布特征。
  - **RQ3**：EvoSL36 中结构和信号路由块变更最多，接口稳定，文档变更少，与原研究结论相同，即工程师更多管理信号数据而非实现算法。

**有效性威胁与相关工作**

- **有效性威胁**：原研究分支情况不明致部分提交未分析；EvoSL 来自 GitHub 可能不具代表性；EvoSL 对 Stateflow 变更研究适用性有限。
- **相关工作**：介绍了 Simulink 模型相关研究、模型演化领域工作及从软件仓库挖掘代码和模型的研究，EvoSL 与前人工作不同，提供了含完整修订历史的项目。

**结论**

EvoSL 是首个包含模型和项目变更的 Simulink 项目大型语料库，开源且含收集分析工具，在其子集上成功复制闭源工业项目模型变更案例研究，对研究社区有重要价值。

### 相关论文2：可复制性研究：用于理解的语料库Simulink模型和项目

[2308.01978v2](https://arxiv.org/pdf/2308.01978v2)

这篇论文是关于 Simulink 模型语料库的可复制性研究，主要目的是调查先前使用 Simulink 模型语料库的实证研究的可重复性，并评估其结果对新的更大语料库的普遍性，包括与专有模型的比较。

**研究背景**

- **Simulink 简介**：Simulink 是一种广泛应用于多个领域的商业工具，工程师可通过其图形化建模环境设计复杂系统模型，支持多种层次结构机制，模型可编译、模拟，并能生成和部署代码。
- **模型复杂度与规模度量**：Simulink 通过扁平化模型计算其复杂度，近期工作显示规模度量在 Simulink 中也有价值。
- **实证研究现状**：开源 Simulink 模型的实证研究有限，相关研究多依赖学术 - 产业合作获取闭源模型，但闭源模型研究结果难以重现或复制。

**研究设计**

- **目标**：深入理解基于模型的开发研究中的可重复性和可复制性，特别是针对 Simulink 模型。提出两个主要研究问题，一是在尝试复制基于模型的开发研究时遇到的挑战和影响；二是先前研究结果在开源或更大数据集上的可推广程度。
- **方法**：利用现有语料库进行样本研究，采用统计学习策略将先前研究结果推广到更大数据集，以 SLNET 语料库为基础，复制早期实证研究并分析其结果。

**研究过程与结果**

1. 语料库概述

   - **SC 语料库**：最初的开源 Simulink 模型语料库，包含多种来源的模型，分为教程、简单、高级和其他类别，部分模型存在许可证问题，且在模型收集和标注过程中存在一些不明确性。
   - **SC20 语料库**：对 SC 项目的重新收集版本，包含更多模型，但在复制包方面存在不足，如缺少 git 仓库和文档，影响结果重现。
   - **SLNET 语料库**：最大的已知 Simulink 语料库，通过特定方式收集，解决了先前语料库的一些问题，如手动项目选择和许可证不清晰等，包含大量模型和项目，且提供了模型的元数据。

   ![image-20241225200201531](https://github.com/Anorexia16/PicStream/releases/download/asd/20241226-115309.jpg)

2. 复制研究结果

   - **模型度量比较**：SLNET 与早期语料库在模型度量方面存在差异，如模型大小、层次结构和编译模型比例等。多数 SLNET 模型较小，但也包含大量非平凡模型，其模型度量分布与早期语料库相似，具有长尾分布特点。
   - 建模实践结果
   - <img src="https://github.com/Anorexia16/PicStream/releases/download/asd/20241226-115310.jpg" alt="image-20241225193526929" style="zoom:80%;" />
   - 该图展示了最常见的块类型在和 SLNET 语料库中的分布情况，通过对比不同语料库中模型的组成特点，可以直观地反映出建模实践中模型的结构特征以及在不同语料库中的共性和差异。
     - **模型引用**：在各语料库中模型引用的使用较为稀疏。
     - **代数环**：代数环出现相对较少。
     - **小类现象**：观察到类似 Java 程序中的 “小类” 现象，子系统中块的中位数数量不超过 11，需进一步研究其对模型质量的影响。
     - **变更研究适用性**：SLNET 项目在模型和项目变更研究方面具有一定潜力，部分项目有协作开发和多版本模型，但也存在大量项目未更新模型的情况。
     - **开源代码生成模型**：SLNET 中配置为可生成代码的模型数量比之前语料库多，但其是否满足研究需求需进一步调查。

**研究结论与展望**

- **结论**：SLNET 语料库确认并反驳了早期研究结果，具有作为模型开发研究有价值语料库的潜力；开源 Simulink 模型遵循良好建模实践，部分与专有模型可比；提出了确定代码生成 Simulink 模型的启发式方法，并提供了 Git 仓库以促进模型演化研究。
- **展望**：未来工作可包括研究模型度量是否可用于预测过程度量，如缺陷预测。

### 当前进展

目前构建了一个存储了共18k个项目，其中包含109k个Simulink模型，超过1500万个模块数据的大型数据库。但作为一个基于MongoDB的Simulink模型库，仍然使用关键词和MongoDB的聚合框架来根据模型的元数据进行多条件查询，并不支持自然语言查询，因此计划与大模型相结合，以增强Simulink模型的检索能力。

### 下一步工作

- 方法1：目前使用MongoDB格式存储Simulink模型元数据，需要对其进行扁平化处理和数据整合，进而利用大语言模型检索相近语义数据。
- 方法2：利用大语言模型，将用户的自然语言查询转化为MongoDB查询语句，并结合基于语义相似度的向量搜索技术，在数据库中搜索与查询向量相似度最高的模型，返回最匹配的结果。

## 模型检索引擎调研与进展

### 相关项目：mindsdb项目

**[mindsdb](https://github.com/mindsdb/mindsdb)**

**介绍**

MindsDB 是一个开源的自动化机器学习平台，专注于将人工智能和机器学习无缝集成到数据库中，使用户可以通过简单的 SQL 查询调用 AI 功能。它的目标是让开发者和分析人员无需深入了解机器学习的复杂细节，就能快速实现预测和智能分析。
**核心功能**

1. 与数据库的无缝集成：MindsDB 支持多种数据库（如 MySQL、PostgreSQL、MongoDB、Snowflake 等），并将机器学习能力直接嵌入到数据库查询流程中。

- 用户可以直接从数据库中提取数据并训练预测模型。
- 查询时可将预测结果与数据库数据结合返回。
- ![image-20241225190357338](https://github.com/Anorexia16/PicStream/releases/download/asd/20241226-115311.jpg)

2. MindsDB与 LLM 集成：该集成允许在 MindsDB 中部署 OpenAI 模型，为模型提供对来自各种数据源的数据的访问。

- OpenAI GPT 系列：处理自然语言输入，生成 SQL 查询并交互。
- Hugging Face 模型：实现自然语言理解、问答或生成任务。
- LangChain：将 LLM 与 MindsDB 集成，构建基于数据驱动的智能应用。

### 当前进展

成功搭建了搜索引擎与MongoDB的结合环境，实现了对Simulink元数据的智能化自然语言分析。

## Simulink 模型切片

### 相关论文：Simulink物理模型复用

论文链接: [Towards the reuse of physical models within the development life-cycle: a case study of Simulink models](https://ieeexplore.ieee.org/abstract/document/9789840)

本文探讨了基于模型的系统工程（MBSE）方法在系统开发生命周期中的应用，尤其关注如何有效重用系统工件。研究提出了一种利用自然语言处理（NLP）技术对MATLAB Simulink模型进行词向量化处理的方案，旨在通过提高信息检索的语义深度来促进模型的重用。研究结果表明，该方法有效地提升了模型的重用效率和信息检索精度。

#### 研究目的

旨在通过PhysicalModel2Simulink解决方案来促进Simulink模型中知识的重用，运用本体论方法对模型进行语义表示、索引以及检索，并验证该方法的有效性，同时指出研究局限与未来工作方向。

#### 研究背景与相关工作

1. **基于模型的系统工程（MBSE）现状**
   MBSE发展迅速，但工程工具在模型重用方面存在欠缺，缺乏有效的高级检索机制，难以充分利用模型蕴含的知识。
   例如，在实际工程应用中，众多工程师面对大量已有的模型，却很难快速精准地找到能复用的部分用于新的项目开发，因为检索工具不够智能高效。
2. **工具间互操作性与设计重用需求**
   不同工具支持多种工程方法，实现工具间的通信（互操作性）以及工程设计的重用，对于节省成本和时间意义重大。像在一个涉及多个专业领域协同的大型工程项目里，不同专业软件生成的模型若能方便地交互和复用，将极大提升整体效率。
3. **已有重用研究的不足**
   已有的研究致力于工程工件的重用，然而在提高系统工件可重用性方面仍面临诸多挑战。比如部分方法是基于领域知识的特定特征，适用范围较窄，还有些仅仅进行文本比较，难以深入挖掘模型的语义等内在关联，导致复用效果不理想。
4. **其他相关探索及本文独特性**
   有的工作对SysML、Modelica等元模型与RSHP元模型进行映射，或在CAD、UML等模型的表示和检索方面进行尝试，但本文提出的针对Simulink模型重用的解决方案有着自身独特之处，聚焦于解决Simulink模型重用这一特定场景下的问题。

#### PhysicalComponent2Simulink系统设计与实现

![PhysicalComponent2Simulink系统设计与实现](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.215157.png)

1. **项目背景与动机**
   在H2020 - AHTOOLs项目中，其用例3聚焦于提高物理模型的可重用性，以支持电子产品工程设计，为欧洲工业提供数字化和自动化解决方案，在此背景下开展相关研究与实践。
2. **RSHP元模型**
   定义了包括Artifact、Knowledge Element、Term、Relationship（RSHP）、Type、Data和Meta - data等元素在内的概念及其关系，有着基于特定语义的规范，并且可通过OSLC - KM接口进行序列化，为后续模型表示等工作奠定基础。
3. **物理模型的语义表示**
   通过定义PMME（Physical Model Mappable Element），以独立于语言的方式来表示物理建模信息，克服物理模型表示的多样性和互操作性难题。PMME具备多种功能以及输出格式，还在项目中提供了信息接口，方便进行数据的交互与运用。
4. **重用物理模型的技术框架**
   运用CAKE API框架，先是把Simulink模型从基于文本的表示转化为基于概念的知识图谱表示，再利用其索引和检索功能，并基于图和模式匹配进行语义相似性计算。同时，PhysicalModel2Simulink组件实现Simulink元素与Mappeable Element的映射，结合Matlab作为COM自动化服务器和CAKE共同构建起整个解决方案的架构。

#### 案例研究：Simulink模型的索引和检索

1. **研究设计**
   从MathWorks网站下载涵盖通用、汽车、航空航天等不同领域的38个Simulink模型构建数据集，并且精心设计了20个包含常见模型组件的查询，之后执行实验，最后分析检索结果的精度、召回率和F1分数等指标。
2. **结果分析**
   ![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.225444.png)
   除了一个查询外，95%的查询精度达到优秀水平，85%的查询召回率达到良好及以上水平，总体平均精度优秀、召回率良好。相较于之前的相关工作，精度提高24%、召回率提高9%、F1提高21%，这充分表明基于语义和拓扑算法计算相似性的方法行之有效，而且还可通过语义聚类和控制词汇等手段进一步改进。
3. **研究局限性**
   当前研究受限于模型库规模以及查询创建方式，后续需要更大的Simulink模型集，同时要更深入地研究用户行为，从而创建更贴合实际情况的查询数据集，并且还需要构建更具体的物理模型领域本体，来让研究更完善。

#### 研究总结与展望

1. **当前成果**
   本研究提出的方法为工程师链接系统工件提供了很有前景的方案，通过案例研究也证实了基于语义表示构建物理模型索引和检索引擎是可行的，在Simulink模型知识重用方面迈出了重要步伐。
2. **未来计划**
   未来打算纳入更多类型的模型（如Altium、Modelica语言的物理模型）开展实验，同时扩大实验规模，使其能更好地满足实际用户需求，进而为方法的有效性提供更可靠的验证，持续推动模型重用相关研究的发展。

### 相关论文：仿真模型重用的方法综述

论文链接：[Approaches for Simulation Model Reuse in Systems Design — A Review](https://www.sae.org/publications/technical-papers/content/2022-01-0355/)

#### 背景与动机

- 在系统设计中，工程师依靠计算机模拟模型辅助决策，但开发新模型成本高、耗时久。尽管模拟软件有可重用模型库，但完全重用存在局限。
- 模型重用能节省成本，其水平分为六级，从直接重用完整模型到完全开发新模型，重用水平越低，成本和发生频率越高。为实现重用，开发阶段需准备工作，重用时要执行一系列任务。

#### 模型重用准备工作

1. **模型特征提取**：
   - 是重用首要步骤，模型特征包括知识、元数据、执行细节和元知识等。不同工程领域提取方式不同，如空间领域、机电一体化领域和汽车领域等各有重点和标准，通常由模型创建者完成。
2. **模型文档编制**：
   - 模型文档是模型特征的有序集合，多为文本文件，也有采用 UML 和流程图等形式。例如汽车工程师协会（SAE）提供的模板，有助于多学科团队重用地面车辆系统模拟模型。
3. **模型组织管理**：
   - 早期基于文本，现多采用层次结构和本体论。层次结构依系统物理分解组织，便于熟悉系统结构的用户查找，但模型多了效率低，常与本体论结合。本体论可形式化知识，分为上层、中层、领域、模型特征和软件特定本体等，存储方式多样，各有利弊。

#### 模型重用执行任务

1. **模型搜索**：
   - 是重用第一步，依赖模型库。用户可通过浏览层次结构、文档或查询搜索模型。层次结构适用于小型库，大型库效率低；文档查找耗时；查询方式包括词相似性引擎、在线搜索引擎和查询语言，各有优缺点，如词相似性引擎功能有限，在线搜索引擎受限于文本查询，查询语言虽功能强大但创建成本高。
2. **模型与组件选择**：
   - 高重用水平下相对简单，低水平时因用户需求与组件特征难以直接匹配而复杂。部分研究提出用启发式方法辅助从算法筛选结果中选择组件，弥补算法在组件选择时的高计算复杂度问题。
3. **模型组件组合**：
   - 将选定组件连接成完整模型，其难度取决于组件的可组合性。可组合性包括语法、语义和语用三个层面，语法层面要求参数兼容和同步执行，部分形式化方法可辅助；语义层面确保有效通信和结果有效，工程模型因多学科和多层次抽象难以确定；语用层面关注是否满足用户目的，通常用启发式方法验证。虽有软件提供工具，但保证语义可组合性仍是挑战，一些标准如 HLA 等有一定规范作用，但也存在局限。
4. **模型适应调整**：
   - 用户常需调整模型或组件以适配需求，可调整的完整模型具有互操作性，程度因模型复杂度而异。如 SysML 支持变体建模，便于快速适应不同配置。
5. **模型验证、核实与认证**：
   - 模型重用前需验证以建立信任，V&V 在重用多个阶段进行，包括选择、组合和适应后。验证方法多样，分为非正式、正式、静态和动态四类，工程师常使用非正式方法。认证由权威机构判断模型可用性，与 V&V 共同影响可信度，但工程模型因复杂很少认证，重用时多依赖启发式方法验证，且验证成本随置信度增加呈指数增长。
6. **模型模拟**：
   - 验证后的模型可用于模拟实验获取预测，模拟比物理原型实验有优势，还可与优化例程结合探索最优解决方案。

#### 研究总结与展望

- 本文综述了模型重用相关内容，明确其能节省成本，但受重用水平影响任务流程。模型准备和重用任务各环节有多种方法和技术，但也存在诸多挑战。
- 未来研究可关注捕获专家在模型重用任务中的启发式方法，以及深入研究模型认证过程，以推动模型重用技术发展。

## Chain-of-thoughts 思维链方法

### 相关论文：大语言模型的零思维推理

论文链接：[Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916v3)

#### 研究背景

- 大规模语言模型在自然语言处理领域变革关键，其成功常与少样本或零样本学习相关，但在复杂多步推理的系统 2 任务上表现不佳。
- 思维链提示技术虽提升了模型在某些推理任务的性能，但以往对模型零样本推理能力的研究不足。

#### Zero-shot-CoT 方法

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.223749.png)

- 在问题前添加如“Let’s think step by step”的提示语，引导模型逐步推理，无需为每个任务制作少样本推理示例，具有通用性。
  ![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.223754.png)
- 采用两阶段提示：先利用模板将问题转换为提示输入模型生成推理路径，再结合新模板提取最终答案，不同任务答案提取模板有差异。

#### 实验设计

- **任务与数据集**：在算术、常识、符号和逻辑推理四类共 12 个数据集（如 SingleEq、CommonsenseQA 等）上评估，涵盖不同难度和类型推理问题。
- **模型与基线**：使用 17 个不同模型（如 InstructGPT、GPT-3、PaLM 等），将 Zero-shot-CoT 与标准零样本、少样本及少样本 CoT 等基线方法对比，采用贪婪解码策略。
  ![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.223832.png)

#### 实验结果

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.223854.png)

- **与零样本基线对比**：在多数算术、符号和其他逻辑推理任务中显著优于标准零样本提示，如在 MultiArith 和 GSM8K 数据集上 175B 的 InstructGPT 模型准确率大幅提升，但在常识推理任务提升不明显，不过推理链多逻辑合理。
- **与其他基线对比**：在基准测试上虽低于 Few-shot-CoT，但优于标准少样本提示。模型规模影响零样本推理，大模型结合思维链推理性能提升显著，小模型效果不佳。
- **鲁棒性分析**：鼓励推理的模板可提高性能，“Let’s think step by step”最佳，误导或无关模板无提升；Few-shot-CoT 示例与任务领域不同但答案格式相同时有一定提升但低于 Zero-shot-CoT。

#### 讨论与相关工作

- 与多数微调或特定任务少样本提示研究不同，证明了 LLMs 的零样本推理能力，Zero-shot-CoT 为研究提供新方向。
- 因训练数据集细节不明，难以确定性能提升原因，但不同模型在多任务中的提升表明非简单记忆，且提示方法受数据偏见影响，但 Zero-shot-CoT 有助于探究模型推理能力。

#### 研究局限与社会影响

- 训练数据集细节不公开，难以分析模型能力提升根源。LLMs 存在捕捉和放大数据偏见问题，提示方法也可能继承，需关注在应用中的公平性和可靠性。

#### 结论

Zero-shot-CoT 方法有效提升了大型语言模型在多种推理任务中的零样本推理能力，为推理任务提供了零样本基线，启发了对多任务提示方法的探索，推动了相关研究。

### 相关论文：数值推理任务

论文链接：[Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks](https://arxiv.org/pdf/2211.12588)

#### 研究背景

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.223643.png)
在人工智能领域，数值推理是一项长期存在且重要的任务。近年来，为了评估深度学习模型的数值/算术推理能力，涌现出大量相关数据集，其中基于数学文字题（MWP）和金融问题的数据集应用广泛。早期研究主要通过从头训练或微调模型来生成中间步骤以获得最终答案，但这种方法需要大量带有专家标注步骤的训练示例。近期，大型语言模型（LLMs）的出现使得通过少量输入 - 输出示例提示模型解决这些任务成为可能，其中思维链（Chain-of-Thoughts，CoT）提示方法在多种文本和数值推理数据集上取得了先进的性能，但该方法在计算方面存在诸多缺陷，如容易出现算术计算错误、无法解决复杂数学表达式以及在表达迭代时效率低下等问题。

#### 程序思维（PoT）方法

- **核心思想**：PoT 旨在将计算与推理分离，利用语言模型（主要是 Codex）生成文本和编程语言语句（如 Python 程序），然后借助外部程序解释器（如 Python 解释器）执行生成的程序来完成计算，从而提高数值推理的准确性。与 CoT 不同，CoT 依赖语言模型同时进行推理和计算，而 PoT 让语言模型专注于用编程语言表达推理过程，将复杂计算委托给外部工具。
  ![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.223720.png)
- **实现方式**：在少样本设置下，通过提供（问题，“程序思维”）对的示例作为演示，引导语言模型学习生成合理的程序。例如，在解决数学问题时，模型会根据示例学习如何定义变量、编写计算步骤等。在零样本设置下，仅提供任务指令，模型直接生成程序并返回答案，无需像零样本 CoT 那样额外提取答案。为了避免模型在零样本 PoT 中退回到在注释中生成推理链而不是程序的情况，通过给“#” token logits 施加一个小的偏差（如 -2）来抑制其生成，从而鼓励模型生成程序。
- **作为中间步骤**：对于一些需要额外文本推理的复杂问题，PoT 可以先生成计算部分的程序并执行得到中间结果，然后将中间结果与问题结合，再通过 CoT 进一步推理得出最终答案。例如在处理涉及时间计算和多阶段推理的问题时，PoT 可以先计算出中间的时间数值，然后 CoT 根据这个结果和问题的其他条件进行后续推理。

#### 实验设计

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.223729.png)

- **数据集与设置**：在五个 MWP 数据集（GSM8K、AQuA、SVAMP、TabMWP、MultiArith）和三个金融数据集（FinQA、ConvFinQA、TATQA）上进行实验。这些数据集的输入格式多样，包括文本、表格和对话等。在构建提示时，对不同格式的输入进行线性化处理，例如将表格转换为特定格式的文本字符串（列用“|”分隔，行用“\n”分隔，空单元格用“-”填充）。实验主要使用 OpenAI Codex（code - davinci - 002）API，同时也对 GPT - 3（text - davinci - 002）、ChatGPT（gpt - turbo - 3.5）、CodeGen、CodeT5 + 和 XGen 等模型进行了消融实验。根据数据集的难度，少样本设置的示例数量在 4 - 8 个之间，如简单的 FinQA 数据集使用较少示例，而复杂的 AQuA 和 TATQA 数据集使用 8 个示例。示例从训练集中选取，并通过在小验证集上调优示例选择来确定最终用于全集评估的最佳 4 - 8 个示例。采用精确匹配分数作为 GSM8K、SVAMP 和 MultiArith 数据集的评估指标，对预测数字进行特定精度的四舍五入后与参考数字比较；对于 AQuA 数据集，先使用 PoT 计算中间答案，再提示语言模型输出最接近的选项来衡量准确性；对于 TabMWP、ConvFinQA 和 TATQA 数据集，使用 Github 上提供的官方评估脚本；对于 FinQA 数据集，由于语言模型在精确计算（特别是高精度浮点数和大数字）方面存在困难，采用相对公差为 0.001 的“math.isclose”来比较答案。同时考虑了多种基线模型和预测策略，包括直接输出答案和通过思维链推导答案，并利用外部计算器对 CoT 生成的方程进行计算（记为 CoT + calc），除了贪婪解码外，还使用自一致性（Wang et al., 2022b）解码策略，对 40 个不同的补全结果进行多数投票作为预测。

#### 实验结果

![img](https://github.com/Anorexia16/PicStream/releases/download/asd2/2024-12-26.223735.png)

    -**少样本结果**：在 MWP 数据集上，PoT 结合贪婪解码在 GSM8K、AQuA、TabMWP 上比 CoT 有超过 8%的提升，在 SVAMP 上提升 4%。在金融 QA 数据集上，PoT 比 CoT 在 FinQA、ConvFinQA 上提升约 20%，在 TATQA 上提升 8%。与 CoT + calc 相比，PoT 表现更优，这是因为 CoT + calc 中外部计算器的后处理步骤较为僵化，在校准计算结果时召回率较低。
    - **少样本 + 自一致性结果**：利用自一致性解码，PoT + SC 在 MWP 数据集上比 CoT + SC 有显著优势，在金融数据集上也有一定提升，如在 FinQA、ConvFinQA 上约提升 20%，在 TATQA 上提升 7%。
    - **零样本结果**：零样本 PoT 在所有 MWP 数据集上显著优于零样本 CoT，平均提升 12%。在 TabMWP 上，零样本 PoT 的性能甚至高于少样本 CoT，显示出其在无需特定数据集示例的情况下泛化到新的数值任务的潜力。

#### 消融研究

- **后端模型分析**：比较不同后端模型（text - davinci - 002、code - davinci - 002、gpt - 3.5 - turbo、codegen - 16B - mono、codegen - 16B - multi、CodeT5 + 和 XGen）在 GSM8K、SVAMP 和 FinQA 数据集上的性能。结果表明，gpt - 3.5 - turbo 表现最佳，能显著超过 codex（code - davinci - 002），而 text - davinci - 002 比 code - davinci - 002 弱，这是因为其基于文本的指令调整削弱了生成代码的能力。开源模型如 codegen 与其他模型相比在不同基准测试中表现明显落后，推测是由于预训练不足和模型规模较小。
- **示例敏感性**：通过对 GSM8K 和 FinQA 数据集进行敏感性分析，发现增加示例数量对 GSM8K 的帮助更大，这是因为 GSM8K 问题的多样性更高。当示例数量较少时，PoT 的性能方差较大，例如当 k = 2 时，两个数据集的性能方差可达 7%，随着示例数量增加，性能变得更加稳定。
- **与 PaL 比较**：将 PoT 与 PaL（Gao et al., 2022）进行比较，结果显示 PoT 在总体上优于 PaL，特别是在 SVAMP 和 ASDIV 数据集上，比 PaL 的提示方法高出 6%。
- **语义绑定和多步推理**：“程序思维”的两个核心特性是多步推理和语义绑定。通过比较去除语义绑定（仅用 a、b、c 等简单变量名）和直接生成最终数学方程的变体，发现去除绑定会降低模型性能，在涉及更多变量的复杂问题（如 GSM8K）上性能下降更明显。同时，提示语言模型直接生成目标方程难度较大，将目标方程分解为多个推理步骤有助于提高性能。
- **错误分析**：将错误分为值接地错误和逻辑生成错误。值接地错误是指模型未能为与问题相关的变量分配正确的值，逻辑生成错误是指模型未能根据定义的变量生成正确的计算过程来回答问题。在 TAT - QA 数据集的 198 个数值推理问题失败案例中，47%是值接地错误，33%是逻辑错误，15%同时存在两种错误，5%认为答案实际上是正确的。多数错误为值接地错误，这在 CoT 等其他方法中也较为常见。

#### 相关工作

- 介绍了自然语言处理中的数学推理相关研究，早期有研究关注模型解决算术/代数问题的能力，近期则有更具挑战性的数据集被提出。LiLA（Mishra et al., 2022）致力于将大量数学数据集组装成统一数据集并标注 Python 程序作为生成目标，但主要关注数据集统一；本文则侧重于研究如何生成“有思考的程序”以激发语言模型的推理能力，并探索无示例情况下解决数学问题的方法。同时，还有研究评估语言模型在特定数据集上合成代码的能力。
- 阐述了 LLMs 的上下文学习相关工作，GPT - 3 展示了强大的少样本预测能力，随着模型规模、数据和计算能力的提升，这种能力得以实现。近期有许多研究训练不同类型的 LLMs，并探究上下文学习的工作原理。与本文类似的工作 BINDER（Cheng et al., 2022）应用 Codex 合成“软”SQL 查询来回答表格问题。
- 说明了利用 LLMs 进行推理链的相关研究，CoT 通过展示“自然语言推理过程”使语言模型能够执行推理任务，后续还有其他工作利用不同方法让语言模型通过中间步骤解决推理任务，如 ReAct 利用搜索引擎增强推理能力。本文的方法可视为通过外部工具（Python）增强 CoT 以实现更稳健的数值推理，同时还有其他同期工作采用混合文本/代码推理来解决数学问题。
- 提及了 PoT 的后续工作，包括 self - critic（Gou et al., 2023）、self - eval（Xie et al., 2023）、plan - and - solve（Wang et al., 2023a）等，这些方法通过自我评估或更详细的规划指令来增强语言模型解决数学问题的能力，并在不同数学推理数据集上取得了一定的改进。此外，还有关于在 transformer 模型中使用工具的相关研究，将 Python 程序推广到更通用的 API 调用，以解决更复杂的现实世界推理和接地问题。

#### 研究讨论与结论

- **讨论**：PoT 方法在解决数学或金融等数值推理问题上表现高效，但对于语义推理任务（如常识推理）可能不是最佳选择，CoT 则更适合解决更广泛的推理任务，未来可研究如何更好地结合两者优势。
- **结论**：通过“程序思维”提示方法，能够激发语言模型生成准确的程序来表达复杂推理过程，并将计算交由外部程序解释器处理，显著提高了语言模型在多个数学数据集上的性能。然而，PoT 也存在一些局限性，如执行生成的代码可能存在安全风险，需要限制模型导入模块；在处理 AQuA 数据集的复杂代数问题时仍有困难，未来研究应关注如何进一步提示语言模型生成适用于高度多样化数学问题的代码。

## 整体总结与下一步工作

通过对Simulink结合大语言模型的研究与实现，完成了以下两大核心任务：

1. 实现了支持Simulink模型元数据的解析、存储和语义检索。
2. 实现搜索引擎与MongoDB的结合环境，实现了对Simulink元数据的智能化自然语言分析。
   未来将进一步优化语义检索能力，并探索更多Simulink与大语言模型结合的可能性。

通过对Simulink模型切片复用技术的研究与思维链（CoT）的研究与实现，完成了以下以下核心任务：

1. 实现了Simulink模型切片复现，优化了原文中的切片方法和流程。
2. 实现了针对Simulink模型CoT思维链的与标注方法的设计与使用，分析了该工具的准确度等能力。

## 参考文献

1. Luitel D, Nejati S, Sabetzadeh M. Requirements-driven Slicing of Simulink Models Using LLMs[J]. arXiv preprint arXiv:2405.01695,2024.
2. Shrestha S L, Csallner C. SLGPT: Using transfer learning to directly generate Simulink model files and find bugs in the Simulink toolchain[C]//Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering. 2021: 260-265.
3. Siddiqa M L, Santos J C S, Tanvirb R H, et al. An Empirical Study of Using Large Language Models for Unit Test Generation[J]. arXiv preprint arXiv:2305.00418, 2023.
4. Steenhoek B, Tufano M, Sundaresan N, et al. Reinforcement learning from automatic feedback for high-quality unit test generation[J]. arXiv preprint arXiv:2310.02368, 2023.
5. Chen M, Tworek J, Jun H, et al. Evaluating large language models trained on code[J]. arXiv preprint arXiv:2107.03374, 2021.
6. Shrestha, A., & Allner, C. (2023). EvoSL: A Large Open-Source Corpus of Simulink Models and Project Changes. Retrieved from [https://ranger.uta.edu/~csallner/papers/Shrestha23EvoSL.pdf](https://ranger.uta.edu/~csallner/papers/Shrestha23EvoSL.pdf)
7. Anonymous. (2023). Reproducibility Study: A Corpus of Simulink Models and Projects for Understanding. Retrieved from [https://arxiv.org/pdf/2308.01978v2](https://arxiv.org/pdf/2308.01978v2)
